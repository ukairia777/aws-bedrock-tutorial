##### ê¸°ë³¸ ì •ë³´ ì…ë ¥ #####
# Streamlit íŒ¨í‚¤ì§€ ì¶”ê°€
import streamlit as st
# PDF reader
from PyPDF2 import PdfReader
# Langchain íŒ¨í‚¤ì§€ë“¤
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import BedrockEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import BedrockChat
from langchain.prompts import PromptTemplate
import boto3
import json

session = boto3.Session()

bedrock = session.client(
    service_name='bedrock-runtime',
    region_name='us-east-1',
    endpoint_url="https://bedrock-runtime.us-east-1.amazonaws.com"
)

##### ë©”ì¸ í•¨ìˆ˜ #####
def main():
    st.title("ğŸ¤– PDF analyzerğŸ“œ")
    st.image('ai.png', width=200)
    # ë©”ì¸ê³µê°„
    st.markdown('---')
    st.subheader("Please upload a PDF file and ask your question.")
    # PDF íŒŒì¼ ë°›ê¸°
    pdf = st.file_uploader(" ", type="pdf")
    if pdf is not None:
        # PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ê¸°
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê¸°
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        chunks = text_splitter.split_text(text)

        st.markdown('---')
        st.subheader("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        # ì‚¬ìš©ì ì§ˆë¬¸ ë°›ê¸°
        user_question = st.text_input("Ask a question about your PDF:")
        if user_question:
            # ì„ë² ë”©/ ì‹œë©˜í‹± ì¸ë±ìŠ¤

            embeddings = BedrockEmbeddings(
                region_name='us-east-1',
                endpoint_url="https://bedrock-runtime.us-east-1.amazonaws.com",
            ) 
            # embeddings = OpenAIEmbeddings(openai_api_key=st.session_state["OPENAI_API"])
            knowledge_base = FAISS.from_texts(chunks, embeddings)
            
            docs = knowledge_base.similarity_search(user_question)

            # ì§ˆë¬¸í•˜ê¸°
            llm = BedrockChat(model_kwargs={"temperature": 0},
                        model_id="anthropic.claude-v2",
                        client=bedrock
                    )

            # í”„ë¡¬í”„íŠ¸
            prompt_template = '''
            prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. You must answer in Korean.

            {context}

            Question: {question}
            Helpful Answer:"""
            '''

            PROMPT = PromptTemplate(
                template=prompt_template, input_variables=["context", "question"]
            )

            chain = load_qa_chain(llm, chain_type="stuff", prompt=PROMPT)
            response = chain.run(input_documents=docs, question=user_question)
            # ë‹µë³€ê²°ê³¼
            st.info(response)

if __name__=='__main__':
    main()