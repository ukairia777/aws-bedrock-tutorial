import streamlit as st
import os 
import openai
from moviepy.editor import VideoFileClip, AudioFileClip
import math
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader

def split_file(filename, interval=120):
    # ë¶„í• ëœ íŒŒì¼ëª…ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    split_filenames = []

    # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì˜¤ë””ì˜¤ ë˜ëŠ” ë¹„ë””ì˜¤ í´ë¦½ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    if filename.endswith(('.mp3', '.m4a', '.wav', '.mpga')):
        clip = AudioFileClip(filename)
    else:
        clip = VideoFileClip(filename)
    
    # íŒŒì¼ì„ ìë¥¼ ì´ ë¶€ë¶„ì˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    total_parts = math.ceil(clip.duration / interval)
    st.write('2ë¶„ ë‹¨ìœ„ë¡œ ì˜ìƒì„ ë‚˜ëˆ„ê¸° ìœ„í•´ì„œ ì´ ' + str(total_parts) + 'ê°œì˜ ì˜ìƒìœ¼ë¡œ ë¶„í• í•´ì•¼ í•©ë‹ˆë‹¤.')

    for part in range(total_parts):
        # ì‹œì‘ ë° ì¢…ë£Œ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        start_time = part * interval
        end_time = min((part + 1) * interval, clip.duration)

        # í´ë¦½ì„ ìë¦…ë‹ˆë‹¤.
        new_clip = clip.subclip(start_time, end_time)

        # ìƒˆ íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        new_filename = f"{filename.rsplit('.', 1)[0]}_part{part + 1}.{filename.rsplit('.', 1)[1]}"
        split_filenames.append(new_filename)

        # ìƒˆ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
        if not filename.endswith(('.mp3', '.m4a', '.wav', '.mpga')):
            new_clip.write_videofile(new_filename, codec="libx264")
        else:
            new_clip.write_audiofile(new_filename)

        st.write(new_filename + ' íŒŒì¼ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.')

    clip.close()

    # ë¶„í• ëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return split_filenames

def summarize(client, text):
    response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Summarize the following in 5 bullet points in korean and in formal language"},
                    {"role": "user", "content": text}
                ]
            )
    return response.choices[0].message.content


def main():

    client = openai.OpenAI(
    api_key = 'ì—¬ëŸ¬ë¶„ë“¤ì˜ OpenAI Keyê°’'
    )

    st.set_page_config(page_title="íšŒì˜ë¡ì„ ì‘ì„±í•˜ëŠ” ì¸ê³µì§€ëŠ¥")
    st.session_state.setdefault("audio_file_path", None)
    st.session_state.setdefault("transcript", None)
    st.title("Meeting Minutes AI ğŸ–‹ï¸")
    st.image('meeting.png', width=300)

    uploaded_file = st.file_uploader("Upload Audio File", type=['mp3', 'mp4', 'mpeg', 'mpga', 
                                                                'm4a', 'wav', 'webm'])

    if st.button("Generate Meeting Minutes") and uploaded_file:
        with st.spinner('Processing...'):
            upload_dir = 'uploads'
            os.makedirs(upload_dir, exist_ok=True)
            file_path = os.path.join(upload_dir, uploaded_file.name)
            with open(file_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            st.session_state.audio_file_path = file_path
            split_filenames = split_file(file_path)

            result = ''

            for sub_file in split_filenames:
                with open(sub_file, 'rb') as audio_file:
                    st.write(sub_file, 'ì„ ë¶„ì„í•©ë‹ˆë‹¤.')
                    st.session_state.transcript = client.audio.transcriptions.create(
                                model="whisper-1",
                                file=audio_file,
                                response_format="text"
                                )
                result += st.session_state.transcript

            file_path = "./youtube_text.txt"
            with open(file_path, 'w') as file:
                # íŒŒì¼ì— ë¬¸ìì—´ì„ ì”ë‹ˆë‹¤.
                file.write(result)

            st.write('ì˜ìƒì˜ ë‚´ìš©ì„ ëª¨ë‘ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤. ì „ì²´ ë‚´ìš©ì„ í˜„ì¬ ê²½ë¡œì— youtube_text.txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì´ì œ íšŒì˜ë¡ ì‘ì„±ì„ ìœ„í•´ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.')
            loader = DirectoryLoader('.', glob="*.txt", loader_cls=TextLoader)
            documents = loader.load()
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            texts = text_splitter.split_documents(documents)
            st.write('ë¶„í• ëœ í…ìŠ¤íŠ¸ì˜ ê°œìˆ˜ :', len(texts))

            final_result = ''
            for t in texts:
                st.write('íšŒì˜ë¡ì„ ì‘ì„± ì¤‘...')
                final_result += summarize(client, str(t))

    if st.session_state.audio_file_path:
        st.subheader("íšŒì˜ë¡")
        st.write(st.session_state.audio_file_path.split("\\")[1])
        if result:
            st.markdown(final_result)

if __name__ == "__main__":
    # openai.api_key = os.getenv("OPENAI_API_KEY")
    main()